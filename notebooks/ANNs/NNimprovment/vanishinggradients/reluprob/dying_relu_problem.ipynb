{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303aef98",
   "metadata": {},
   "source": [
    "## **DYING RELU PROBLEM**\n",
    "- *using variable learning rate*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9cd01",
   "metadata": {},
   "source": [
    "\n",
    "### Layer-wise Dying ReLU Check on MNIST (0.1 LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ff4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2caeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f976163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Layers\n",
    "inputs = Input(shape=(784,))\n",
    "x = Dense(128,activation='relu',name = 'dense_1')(inputs)\n",
    "x = Dense(64,activation='relu', name = 'dense_2')(x)\n",
    "x = Dense(32, activation='relu', name = 'dense_3')(x)\n",
    "outputs = Dense(10, activation='softmax', name = 'output')(x)\n",
    "\n",
    "model_1 = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23eb213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_1 = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "model_1.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = optimizer_1,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2641788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5141 - loss: 1.4670 - val_accuracy: 0.6313 - val_loss: 1.1877\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4776 - loss: 1.3616 - val_accuracy: 0.5157 - val_loss: 1.2196\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4795 - loss: 1.3563 - val_accuracy: 0.3321 - val_loss: 1.8514\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4091 - loss: 1.4821 - val_accuracy: 0.3195 - val_loss: 1.5652\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3549 - loss: 1.5728 - val_accuracy: 0.3809 - val_loss: 1.5714\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820de160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute fraction of dead neurons in a given layer\n",
    "def dead_neurons_fraction(model, layer_index, sample_data):\n",
    "    activation_model = Model(inputs=model.input, outputs=model.layers[layer_index].output)\n",
    "    activations = activation_model.predict(sample_data, verbose=0)\n",
    "    dead_frac = np.mean(np.all(activations == 0, axis=0))\n",
    "    return dead_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d0dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify ReLU layers safely\n",
    "relu_layers_1 = [\n",
    "    i for i, layer in enumerate(model_1.layers)\n",
    "    if hasattr(layer, 'activation') and layer.activation.__name__ == 'relu'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b2a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer-wise Dead ReLU Analysis:\n",
      "Layer dense_1: 96.88% neurons are dead\n",
      "Layer dense_2: 90.62% neurons are dead\n",
      "Layer dense_3: 87.50% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 38.09%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLayer-wise Dead ReLU Analysis:\")\n",
    "for idx in relu_layers_1:\n",
    "    dead_frac = dead_neurons_fraction(model_1, idx, x_train[:1000])\n",
    "    print(f\"Layer {model_1.layers[idx].name}: {dead_frac * 100:.2f}% neurons are dead\")\n",
    "\n",
    "# Final accuracy summary\n",
    "final_acc = history_1.history[\"val_accuracy\"][-1]\n",
    "print(f\"\\nFinal Validation Accuracy: {final_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f509f",
   "metadata": {},
   "source": [
    "### Dying ReLU Check on MNIST (0.01 LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caffa63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_2 = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfdbe004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Layers\n",
    "inputs = Input(shape=(784,))\n",
    "x = Dense(128,activation='relu',name = 'dense_1')(inputs)\n",
    "x = Dense(64,activation='relu', name = 'dense_2')(x)\n",
    "x = Dense(32, activation='relu', name = 'dense_3')(x)\n",
    "outputs = Dense(10, activation='softmax', name = 'output')(x)\n",
    "\n",
    "model_2 = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fa526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='categorical_crossentropy', optimizer= optimizer_2, metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b813a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2988 - val_accuracy: 0.9532 - val_loss: 0.1671\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1430 - val_accuracy: 0.9601 - val_loss: 0.1359\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1126 - val_accuracy: 0.9621 - val_loss: 0.1308\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0929 - val_accuracy: 0.9678 - val_loss: 0.1173\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0841 - val_accuracy: 0.9707 - val_loss: 0.1122\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 5,\n",
    "    validation_split =0.2,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9190f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer-wise Dead ReLU Analysis:\n",
      "Layer dense_1: 28.12% neurons are dead\n",
      "Layer dense_2: 15.62% neurons are dead\n",
      "Layer dense_3: 18.75% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 97.07%\n"
     ]
    }
   ],
   "source": [
    "# Identify ReLU layers safely\n",
    "relu_layers_2 = [\n",
    "    i for i, layer in enumerate(model_2.layers)\n",
    "    if hasattr(layer, 'activation') and layer.activation.__name__ == 'relu'\n",
    "]\n",
    "\n",
    "print(\"\\nLayer-wise Dead ReLU Analysis:\")\n",
    "for idx in relu_layers_2:\n",
    "    dead_frac = dead_neurons_fraction(model_2, idx, x_train[:1000])\n",
    "    print(f\"Layer {model_2.layers[idx].name}: {dead_frac * 100:.2f}% neurons are dead\")\n",
    "\n",
    "# Final accuracy summary\n",
    "final_acc = history_2.history[\"val_accuracy\"][-1]\n",
    "print(f\"\\nFinal Validation Accuracy: {final_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29591ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1059 - loss: 110.2047 - val_accuracy: 0.0997 - val_loss: 2.3082\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1051 - loss: 2.3124 - val_accuracy: 0.1081 - val_loss: 2.3196\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1025 - loss: 2.3121 - val_accuracy: 0.0914 - val_loss: 2.3223\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1031 - loss: 2.3140 - val_accuracy: 0.1060 - val_loss: 2.3253\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1039 - loss: 2.3151 - val_accuracy: 0.1060 - val_loss: 2.3127\n",
      "\n",
      "Layer-wise Dead ReLU Analysis for model with Learning Rate: 0.5\n",
      "Layer dense_1: 98.44% neurons are dead\n",
      "Layer dense_2: 96.88% neurons are dead\n",
      "Layer dense_3: 100.00% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 10.60%\n",
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1094 - loss: 2.9606 - val_accuracy: 0.1060 - val_loss: 2.3025\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1090 - loss: 2.3034 - val_accuracy: 0.1060 - val_loss: 2.3051\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1101 - loss: 2.3042 - val_accuracy: 0.1035 - val_loss: 2.3060\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1082 - loss: 2.3044 - val_accuracy: 0.1060 - val_loss: 2.3031\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1065 - loss: 2.3048 - val_accuracy: 0.1060 - val_loss: 2.3086\n",
      "\n",
      "Layer-wise Dead ReLU Analysis for model with Learning Rate: 0.1\n",
      "Layer dense_1: 93.75% neurons are dead\n",
      "Layer dense_2: 100.00% neurons are dead\n",
      "Layer dense_3: 100.00% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 10.60%\n",
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2949 - val_accuracy: 0.9512 - val_loss: 0.1678\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1318 - val_accuracy: 0.9616 - val_loss: 0.1374\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0975 - val_accuracy: 0.9601 - val_loss: 0.1424\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0798 - val_accuracy: 0.9697 - val_loss: 0.1086\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0683 - val_accuracy: 0.9709 - val_loss: 0.1054\n",
      "\n",
      "Layer-wise Dead ReLU Analysis for model with Learning Rate: 0.01\n",
      "Layer dense_1: 16.41% neurons are dead\n",
      "Layer dense_2: 9.38% neurons are dead\n",
      "Layer dense_3: 15.62% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 97.09%\n",
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.5222 - val_accuracy: 0.9430 - val_loss: 0.2093\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1869 - val_accuracy: 0.9578 - val_loss: 0.1523\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1350 - val_accuracy: 0.9635 - val_loss: 0.1243\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1029 - val_accuracy: 0.9578 - val_loss: 0.1392\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0845 - val_accuracy: 0.9695 - val_loss: 0.1043\n",
      "\n",
      "Layer-wise Dead ReLU Analysis for model with Learning Rate: 0.001\n",
      "Layer dense_1: 0.00% neurons are dead\n",
      "Layer dense_2: 9.38% neurons are dead\n",
      "Layer dense_3: 12.50% neurons are dead\n",
      "\n",
      "Final Validation Accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.5,0.1,0.01,0.001]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    \n",
    "    #define layers\n",
    "    inputs = Input(shape=(784,))\n",
    "    x = Dense(128,activation='relu',name = 'dense_1')(inputs)\n",
    "    x = Dense(64,activation='relu', name = 'dense_2')(x)\n",
    "    x = Dense(32, activation='relu', name = 'dense_3')(x)\n",
    "    outputs = Dense(10, activation='softmax', name = 'output')(x)\n",
    "    \n",
    "    #define model\n",
    "    _model = Model(inputs,outputs)\n",
    "    \n",
    "    #define optimizer\n",
    "    _optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    #compile the model\n",
    "    _model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer= _optimizer)\n",
    "    \n",
    "    #Train the model\n",
    "    _history = _model.fit(x_train,y_train,validation_split = 0.2, epochs = 5, batch_size = 256)\n",
    "    \n",
    "    # Identify ReLU layers safely\n",
    "    _relu_layers = [\n",
    "        i for i, layer in enumerate(_model.layers)\n",
    "        if hasattr(layer, 'activation') and layer.activation.__name__ == 'relu'\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nLayer-wise Dead ReLU Analysis for model with Learning Rate: {lr}\")\n",
    "    for idx in _relu_layers:\n",
    "        dead_frac = dead_neurons_fraction(_model, idx, x_train[:1000])\n",
    "        print(f\"Layer {_model.layers[idx].name}: {dead_frac * 100:.2f}% neurons are dead\")\n",
    "\n",
    "    # Final accuracy summary\n",
    "    final_acc = _history.history[\"val_accuracy\"][-1]\n",
    "    print(f\"\\nFinal Validation Accuracy: {final_acc * 100:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc9b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
