{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7129cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f77381",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cc1195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591ee122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = data_df.drop('Outcome',axis=1), data_df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e15b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d21e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d8a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(8,))\n",
    "x = Dense(32)(input_layer)\n",
    "x = Activation('relu')(x)\n",
    "output_layer = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "base_model = Model(inputs=input_layer,outputs=output_layer)\n",
    "base_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833bbd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5961 - loss: 0.6784 - val_accuracy: 0.5714 - val_loss: 0.7094\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6140 - loss: 0.6657 - val_accuracy: 0.5844 - val_loss: 0.6959\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6270 - loss: 0.6536 - val_accuracy: 0.6299 - val_loss: 0.6834\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6498 - loss: 0.6420 - val_accuracy: 0.6234 - val_loss: 0.6718\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6629 - loss: 0.6317 - val_accuracy: 0.6494 - val_loss: 0.6608\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6678 - loss: 0.6217 - val_accuracy: 0.6558 - val_loss: 0.6505\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6840 - loss: 0.6126 - val_accuracy: 0.6753 - val_loss: 0.6409\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6889 - loss: 0.6040 - val_accuracy: 0.6948 - val_loss: 0.6321\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6922 - loss: 0.5957 - val_accuracy: 0.6948 - val_loss: 0.6238\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7036 - loss: 0.5885 - val_accuracy: 0.7013 - val_loss: 0.6162\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7101 - loss: 0.5815 - val_accuracy: 0.6948 - val_loss: 0.6091\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7166 - loss: 0.5750 - val_accuracy: 0.7078 - val_loss: 0.6026\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7280 - loss: 0.5688 - val_accuracy: 0.7013 - val_loss: 0.5966\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7313 - loss: 0.5632 - val_accuracy: 0.7208 - val_loss: 0.5909\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7362 - loss: 0.5578 - val_accuracy: 0.7273 - val_loss: 0.5857\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7459 - loss: 0.5527 - val_accuracy: 0.7273 - val_loss: 0.5810\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7443 - loss: 0.5481 - val_accuracy: 0.7273 - val_loss: 0.5763\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7476 - loss: 0.5436 - val_accuracy: 0.7273 - val_loss: 0.5720\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7508 - loss: 0.5393 - val_accuracy: 0.7338 - val_loss: 0.5679\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7476 - loss: 0.5353 - val_accuracy: 0.7403 - val_loss: 0.5640\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7476 - loss: 0.5313 - val_accuracy: 0.7403 - val_loss: 0.5604\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7476 - loss: 0.5277 - val_accuracy: 0.7403 - val_loss: 0.5567\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7459 - loss: 0.5241 - val_accuracy: 0.7468 - val_loss: 0.5535\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7427 - loss: 0.5208 - val_accuracy: 0.7532 - val_loss: 0.5501\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7459 - loss: 0.5176 - val_accuracy: 0.7532 - val_loss: 0.5470\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7459 - loss: 0.5145 - val_accuracy: 0.7532 - val_loss: 0.5440\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7443 - loss: 0.5114 - val_accuracy: 0.7532 - val_loss: 0.5413\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7443 - loss: 0.5085 - val_accuracy: 0.7532 - val_loss: 0.5387\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7443 - loss: 0.5059 - val_accuracy: 0.7597 - val_loss: 0.5362\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7476 - loss: 0.5032 - val_accuracy: 0.7532 - val_loss: 0.5339\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7508 - loss: 0.5007 - val_accuracy: 0.7532 - val_loss: 0.5320\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7557 - loss: 0.4983 - val_accuracy: 0.7532 - val_loss: 0.5299\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7606 - loss: 0.4959 - val_accuracy: 0.7532 - val_loss: 0.5280\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7606 - loss: 0.4937 - val_accuracy: 0.7597 - val_loss: 0.5262\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7638 - loss: 0.4916 - val_accuracy: 0.7662 - val_loss: 0.5244\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7638 - loss: 0.4893 - val_accuracy: 0.7662 - val_loss: 0.5228\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7638 - loss: 0.4874 - val_accuracy: 0.7662 - val_loss: 0.5212\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7622 - loss: 0.4853 - val_accuracy: 0.7662 - val_loss: 0.5197\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7622 - loss: 0.4835 - val_accuracy: 0.7662 - val_loss: 0.5182\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7638 - loss: 0.4815 - val_accuracy: 0.7727 - val_loss: 0.5168\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7622 - loss: 0.4797 - val_accuracy: 0.7727 - val_loss: 0.5155\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7655 - loss: 0.4780 - val_accuracy: 0.7727 - val_loss: 0.5141\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7655 - loss: 0.4763 - val_accuracy: 0.7792 - val_loss: 0.5126\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7671 - loss: 0.4746 - val_accuracy: 0.7857 - val_loss: 0.5114\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7704 - loss: 0.4730 - val_accuracy: 0.7857 - val_loss: 0.5102\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7704 - loss: 0.4715 - val_accuracy: 0.7922 - val_loss: 0.5089\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7687 - loss: 0.4700 - val_accuracy: 0.7922 - val_loss: 0.5078\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7687 - loss: 0.4686 - val_accuracy: 0.7922 - val_loss: 0.5068\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7687 - loss: 0.4672 - val_accuracy: 0.7922 - val_loss: 0.5059\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7687 - loss: 0.4658 - val_accuracy: 0.7922 - val_loss: 0.5051\n"
     ]
    }
   ],
   "source": [
    "base_model_hist = base_model.fit(X_train,y_train,epochs=50,batch_size=256,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ec2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\demo_tuner\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 1. Create model-building function\n",
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune number of hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(layers.Dense(\n",
    "            units = hp.Int(f\"units_{i}\", min_value=16, max_value=256, step=16),\n",
    "            activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Tune learning rate for Adam\n",
    "    lr = hp.Choice(\"learning_rate\", [1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 2. Select tuner (RandomSearch / Hyperband / BayesianOptimization)\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,      # how many hp combinations\n",
    "    executions_per_trial=1,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"demo_tuner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b658a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Search best hyperparameters\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43134c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'num_layers': 1, 'units_0': 192, 'activation': 'tanh', 'learning_rate': 0.001, 'units_1': 144, 'units_2': 240, 'units_3': 224}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adhab\\OneDrive\\Desktop\\VsCode\\DataScience\\Deep Learning\\deeplen\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# 4. Get best model and best hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e0b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7883 - loss: 0.4473 - val_accuracy: 0.7468 - val_loss: 0.5064\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4472 - val_accuracy: 0.7468 - val_loss: 0.5080\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4470 - val_accuracy: 0.7468 - val_loss: 0.5082\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7915 - loss: 0.4467 - val_accuracy: 0.7468 - val_loss: 0.5065\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7932 - loss: 0.4470 - val_accuracy: 0.7662 - val_loss: 0.5054\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4463 - val_accuracy: 0.7662 - val_loss: 0.5049\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7932 - loss: 0.4460 - val_accuracy: 0.7662 - val_loss: 0.5047\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7866 - loss: 0.4460 - val_accuracy: 0.7532 - val_loss: 0.5051\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7899 - loss: 0.4455 - val_accuracy: 0.7468 - val_loss: 0.5042\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4452 - val_accuracy: 0.7597 - val_loss: 0.5034\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7899 - loss: 0.4452 - val_accuracy: 0.7597 - val_loss: 0.5031\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7866 - loss: 0.4451 - val_accuracy: 0.7532 - val_loss: 0.5048\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7850 - loss: 0.4455 - val_accuracy: 0.7468 - val_loss: 0.5059\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7850 - loss: 0.4450 - val_accuracy: 0.7532 - val_loss: 0.5063\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7850 - loss: 0.4445 - val_accuracy: 0.7403 - val_loss: 0.5083\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7850 - loss: 0.4442 - val_accuracy: 0.7403 - val_loss: 0.5089\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7883 - loss: 0.4442 - val_accuracy: 0.7403 - val_loss: 0.5096\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7883 - loss: 0.4439 - val_accuracy: 0.7403 - val_loss: 0.5101\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7866 - loss: 0.4437 - val_accuracy: 0.7403 - val_loss: 0.5100\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7850 - loss: 0.4434 - val_accuracy: 0.7468 - val_loss: 0.5094\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7834 - loss: 0.4440 - val_accuracy: 0.7468 - val_loss: 0.5082\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7883 - loss: 0.4433 - val_accuracy: 0.7468 - val_loss: 0.5073\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7899 - loss: 0.4429 - val_accuracy: 0.7403 - val_loss: 0.5077\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7932 - loss: 0.4427 - val_accuracy: 0.7468 - val_loss: 0.5069\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7915 - loss: 0.4424 - val_accuracy: 0.7468 - val_loss: 0.5051\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7932 - loss: 0.4423 - val_accuracy: 0.7403 - val_loss: 0.5040\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7932 - loss: 0.4416 - val_accuracy: 0.7403 - val_loss: 0.5024\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7932 - loss: 0.4415 - val_accuracy: 0.7468 - val_loss: 0.5023\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7915 - loss: 0.4417 - val_accuracy: 0.7468 - val_loss: 0.5023\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7899 - loss: 0.4413 - val_accuracy: 0.7468 - val_loss: 0.5042\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4409 - val_accuracy: 0.7468 - val_loss: 0.5059\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7866 - loss: 0.4407 - val_accuracy: 0.7403 - val_loss: 0.5070\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7850 - loss: 0.4403 - val_accuracy: 0.7403 - val_loss: 0.5080\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7866 - loss: 0.4404 - val_accuracy: 0.7273 - val_loss: 0.5096\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7883 - loss: 0.4403 - val_accuracy: 0.7338 - val_loss: 0.5088\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.4400 - val_accuracy: 0.7403 - val_loss: 0.5071\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7899 - loss: 0.4398 - val_accuracy: 0.7403 - val_loss: 0.5040\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.4396 - val_accuracy: 0.7403 - val_loss: 0.5022\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7866 - loss: 0.4392 - val_accuracy: 0.7468 - val_loss: 0.5025\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4390 - val_accuracy: 0.7532 - val_loss: 0.5026\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7915 - loss: 0.4387 - val_accuracy: 0.7532 - val_loss: 0.5026\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7899 - loss: 0.4385 - val_accuracy: 0.7532 - val_loss: 0.5033\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7866 - loss: 0.4383 - val_accuracy: 0.7532 - val_loss: 0.5051\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7866 - loss: 0.4384 - val_accuracy: 0.7403 - val_loss: 0.5076\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.4383 - val_accuracy: 0.7403 - val_loss: 0.5076\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7866 - loss: 0.4381 - val_accuracy: 0.7468 - val_loss: 0.5071\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7866 - loss: 0.4377 - val_accuracy: 0.7468 - val_loss: 0.5073\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7866 - loss: 0.4374 - val_accuracy: 0.7468 - val_loss: 0.5070\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7883 - loss: 0.4373 - val_accuracy: 0.7468 - val_loss: 0.5064\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7866 - loss: 0.4367 - val_accuracy: 0.7338 - val_loss: 0.5060\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7850 - loss: 0.4365 - val_accuracy: 0.7468 - val_loss: 0.5043\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7932 - loss: 0.4365 - val_accuracy: 0.7597 - val_loss: 0.5025\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7948 - loss: 0.4362 - val_accuracy: 0.7597 - val_loss: 0.5018\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7932 - loss: 0.4360 - val_accuracy: 0.7532 - val_loss: 0.5010\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7915 - loss: 0.4354 - val_accuracy: 0.7468 - val_loss: 0.5020\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7932 - loss: 0.4354 - val_accuracy: 0.7532 - val_loss: 0.5017\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7915 - loss: 0.4352 - val_accuracy: 0.7532 - val_loss: 0.5004\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7932 - loss: 0.4355 - val_accuracy: 0.7597 - val_loss: 0.4993\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7932 - loss: 0.4351 - val_accuracy: 0.7532 - val_loss: 0.4976\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7899 - loss: 0.4350 - val_accuracy: 0.7468 - val_loss: 0.4975\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7883 - loss: 0.4348 - val_accuracy: 0.7597 - val_loss: 0.4974\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7883 - loss: 0.4344 - val_accuracy: 0.7597 - val_loss: 0.4975\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7899 - loss: 0.4342 - val_accuracy: 0.7597 - val_loss: 0.4980\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7915 - loss: 0.4341 - val_accuracy: 0.7532 - val_loss: 0.5002\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7915 - loss: 0.4340 - val_accuracy: 0.7468 - val_loss: 0.5019\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.4336 - val_accuracy: 0.7468 - val_loss: 0.5041\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7834 - loss: 0.4334 - val_accuracy: 0.7403 - val_loss: 0.5054\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7850 - loss: 0.4333 - val_accuracy: 0.7468 - val_loss: 0.5059\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7866 - loss: 0.4332 - val_accuracy: 0.7532 - val_loss: 0.5059\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7883 - loss: 0.4332 - val_accuracy: 0.7597 - val_loss: 0.5052\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7883 - loss: 0.4329 - val_accuracy: 0.7597 - val_loss: 0.5055\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7883 - loss: 0.4326 - val_accuracy: 0.7597 - val_loss: 0.5034\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7899 - loss: 0.4325 - val_accuracy: 0.7597 - val_loss: 0.5015\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7899 - loss: 0.4323 - val_accuracy: 0.7532 - val_loss: 0.5008\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7883 - loss: 0.4320 - val_accuracy: 0.7532 - val_loss: 0.5010\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7883 - loss: 0.4316 - val_accuracy: 0.7468 - val_loss: 0.5010\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7866 - loss: 0.4316 - val_accuracy: 0.7403 - val_loss: 0.5008\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7915 - loss: 0.4312 - val_accuracy: 0.7403 - val_loss: 0.5012\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7866 - loss: 0.4310 - val_accuracy: 0.7468 - val_loss: 0.5034\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7899 - loss: 0.4309 - val_accuracy: 0.7532 - val_loss: 0.5051\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7850 - loss: 0.4313 - val_accuracy: 0.7532 - val_loss: 0.5056\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7850 - loss: 0.4314 - val_accuracy: 0.7597 - val_loss: 0.5045\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7899 - loss: 0.4308 - val_accuracy: 0.7468 - val_loss: 0.5022\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7932 - loss: 0.4306 - val_accuracy: 0.7468 - val_loss: 0.4999\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7883 - loss: 0.4304 - val_accuracy: 0.7597 - val_loss: 0.4992\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7915 - loss: 0.4301 - val_accuracy: 0.7597 - val_loss: 0.4982\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7932 - loss: 0.4297 - val_accuracy: 0.7597 - val_loss: 0.5002\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7915 - loss: 0.4292 - val_accuracy: 0.7597 - val_loss: 0.5016\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7899 - loss: 0.4287 - val_accuracy: 0.7532 - val_loss: 0.5036\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7866 - loss: 0.4291 - val_accuracy: 0.7403 - val_loss: 0.5064\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7883 - loss: 0.4291 - val_accuracy: 0.7532 - val_loss: 0.5077\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7883 - loss: 0.4289 - val_accuracy: 0.7532 - val_loss: 0.5077\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7883 - loss: 0.4286 - val_accuracy: 0.7403 - val_loss: 0.5068\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7883 - loss: 0.4282 - val_accuracy: 0.7403 - val_loss: 0.5074\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7932 - loss: 0.4277 - val_accuracy: 0.7403 - val_loss: 0.5077\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7915 - loss: 0.4276 - val_accuracy: 0.7403 - val_loss: 0.5078\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7866 - loss: 0.4275 - val_accuracy: 0.7403 - val_loss: 0.5070\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7899 - loss: 0.4272 - val_accuracy: 0.7338 - val_loss: 0.5069\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7948 - loss: 0.4272 - val_accuracy: 0.7338 - val_loss: 0.5074\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7948 - loss: 0.4270 - val_accuracy: 0.7338 - val_loss: 0.5080\n"
     ]
    }
   ],
   "source": [
    "best_model_hist = best_model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b38a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x282bfa5e480>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_model_hist.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(best_model_hist.history['val_accuracy'], label='Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c78f9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. TUNE INPUT LAYER NEURONS\n",
    "    # -------------------------------\n",
    "    input_neurons = hp.Int(\"input_neurons\", min_value=16, max_value=256, step=16)\n",
    "    model.add(layers.Dense(input_neurons, \n",
    "                           activation=hp.Choice(\"input_activation\", [\"relu\", \"tanh\", \"selu\", \"gelu\"]),\n",
    "                           input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    # Optional BatchNorm after input layer\n",
    "    if hp.Boolean(\"input_batchnorm\"):\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Optional Dropout after input layer\n",
    "    model.add(layers.Dropout(hp.Float(\"input_dropout\", 0.0, 0.5, step=0.1)))\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. TUNE HIDDEN LAYERS\n",
    "    # -------------------------------\n",
    "    num_layers = hp.Int(\"num_hidden_layers\", 1, 5)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "\n",
    "        # neurons per layer\n",
    "        units = hp.Int(f\"units_{i}\", min_value=16, max_value=512, step=16)\n",
    "\n",
    "        # activation function\n",
    "        activation = hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"selu\", \"gelu\"])\n",
    "\n",
    "        model.add(layers.Dense(units, activation=activation))\n",
    "\n",
    "        # BatchNorm decision\n",
    "        if hp.Boolean(f\"batchnorm_{i}\"):\n",
    "            model.add(layers.BatchNormalization())\n",
    "\n",
    "        # Dropout layer\n",
    "        dropout_rate = hp.Float(f\"dropout_{i}\", 0.0, 0.6, step=0.1)\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. OUTPUT LAYER\n",
    "    # -------------------------------\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. TUNE OPTIMIZER + LEARNING RATE\n",
    "    # -------------------------------\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\", \"nadam\"])\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = keras.optimizers.SGD(lr, momentum=hp.Float(\"sgd_momentum\", 0.0, 0.9, step=0.1))\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Nadam(lr)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03eea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adhab\\OneDrive\\Desktop\\VsCode\\DataScience\\Deep Learning\\deeplen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5. TUNER SETTINGS\n",
    "# -------------------------------\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    directory=\"tuner_dir\",\n",
    "    project_name=\"advanced_tuner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee6f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 6. EARLY STOPPING DURING SEARCH\n",
    "# -------------------------------\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d76680b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.5609756112098694\n",
      "\n",
      "Best val_accuracy So Far: 0.7886179089546204\n",
      "Total elapsed time: 00h 06m 11s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fa812f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "{'input_neurons': 192, 'input_activation': 'gelu', 'input_batchnorm': False, 'input_dropout': 0.1, 'num_hidden_layers': 1, 'units_0': 368, 'activation_0': 'gelu', 'batchnorm_0': False, 'dropout_0': 0.1, 'learning_rate': 0.004535404569699291, 'optimizer': 'rmsprop', 'units_1': 416, 'activation_1': 'relu', 'batchnorm_1': False, 'dropout_1': 0.2, 'units_2': 400, 'activation_2': 'relu', 'batchnorm_2': True, 'dropout_2': 0.2, 'units_3': 464, 'activation_3': 'gelu', 'batchnorm_3': False, 'dropout_3': 0.0, 'units_4': 192, 'activation_4': 'tanh', 'batchnorm_4': True, 'dropout_4': 0.2, 'sgd_momentum': 0.30000000000000004, 'tuner/epochs': 30, 'tuner/initial_epoch': 10, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0047'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adhab\\OneDrive\\Desktop\\VsCode\\DataScience\\Deep Learning\\deeplen\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\adhab\\OneDrive\\Desktop\\VsCode\\DataScience\\Deep Learning\\deeplen\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 8 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 7. GET BEST MODEL\n",
    "# -------------------------------\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_hp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "966eac75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8013 - loss: 0.4119 - val_accuracy: 0.7662 - val_loss: 0.6302\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4009 - val_accuracy: 0.7273 - val_loss: 0.6960\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.3832 - val_accuracy: 0.7078 - val_loss: 0.6597\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.3855 - val_accuracy: 0.7727 - val_loss: 0.6062\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.3795 - val_accuracy: 0.7532 - val_loss: 0.6058\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.3794 - val_accuracy: 0.7403 - val_loss: 0.6561\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3628 - val_accuracy: 0.7792 - val_loss: 0.6648\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8274 - loss: 0.3601 - val_accuracy: 0.7273 - val_loss: 0.7484\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.3800 - val_accuracy: 0.7792 - val_loss: 0.6181\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.3764 - val_accuracy: 0.7468 - val_loss: 0.6081\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3607 - val_accuracy: 0.7597 - val_loss: 0.6611\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8290 - loss: 0.3634 - val_accuracy: 0.7597 - val_loss: 0.6735\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 0.3546 - val_accuracy: 0.7597 - val_loss: 0.6247\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.3492 - val_accuracy: 0.7857 - val_loss: 0.6094\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.3515 - val_accuracy: 0.7403 - val_loss: 0.6920\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.3519 - val_accuracy: 0.7662 - val_loss: 0.6369\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3496 - val_accuracy: 0.7468 - val_loss: 0.6871\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.3367 - val_accuracy: 0.7597 - val_loss: 0.7082\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.3326 - val_accuracy: 0.7597 - val_loss: 0.6356\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.3293 - val_accuracy: 0.7403 - val_loss: 0.7339\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3309 - val_accuracy: 0.7013 - val_loss: 0.7228\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3183 - val_accuracy: 0.7208 - val_loss: 0.7038\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.3206 - val_accuracy: 0.7013 - val_loss: 0.7377\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3114 - val_accuracy: 0.7143 - val_loss: 0.7595\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3115 - val_accuracy: 0.7403 - val_loss: 0.7678\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8534 - loss: 0.3189 - val_accuracy: 0.7338 - val_loss: 0.7763\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.3095 - val_accuracy: 0.7338 - val_loss: 0.8584\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.3068 - val_accuracy: 0.7078 - val_loss: 0.8394\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8713 - loss: 0.3043 - val_accuracy: 0.7532 - val_loss: 0.7976\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.3024 - val_accuracy: 0.7143 - val_loss: 0.7451\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.2928 - val_accuracy: 0.7143 - val_loss: 0.8834\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2840 - val_accuracy: 0.7013 - val_loss: 0.8103\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.2873 - val_accuracy: 0.7143 - val_loss: 0.8653\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.2980 - val_accuracy: 0.7143 - val_loss: 0.8382\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.2857 - val_accuracy: 0.7078 - val_loss: 0.8517\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8844 - loss: 0.2862 - val_accuracy: 0.7013 - val_loss: 0.9559\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2774 - val_accuracy: 0.7338 - val_loss: 0.8808\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8811 - loss: 0.2648 - val_accuracy: 0.6883 - val_loss: 1.0311\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.2616 - val_accuracy: 0.6883 - val_loss: 1.0404\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2621 - val_accuracy: 0.7273 - val_loss: 0.8612\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2477 - val_accuracy: 0.7013 - val_loss: 0.8990\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.2625 - val_accuracy: 0.6818 - val_loss: 0.9543\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.2462 - val_accuracy: 0.7078 - val_loss: 0.9424\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8990 - loss: 0.2450 - val_accuracy: 0.6818 - val_loss: 0.9579\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.2237 - val_accuracy: 0.7013 - val_loss: 0.9425\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8958 - loss: 0.2488 - val_accuracy: 0.7078 - val_loss: 1.0195\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.2153 - val_accuracy: 0.7208 - val_loss: 1.1307\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.2335 - val_accuracy: 0.6818 - val_loss: 1.2180\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2216 - val_accuracy: 0.7338 - val_loss: 1.1949\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2097 - val_accuracy: 0.7013 - val_loss: 1.2274\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.1954 - val_accuracy: 0.7078 - val_loss: 1.2855\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2035 - val_accuracy: 0.7338 - val_loss: 1.1775\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2086 - val_accuracy: 0.7143 - val_loss: 1.1783\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1757 - val_accuracy: 0.6948 - val_loss: 1.3638\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.1966 - val_accuracy: 0.6753 - val_loss: 1.3553\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.1758 - val_accuracy: 0.7208 - val_loss: 1.4860\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.1904 - val_accuracy: 0.6883 - val_loss: 1.2602\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1962 - val_accuracy: 0.7078 - val_loss: 1.1872\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.1849 - val_accuracy: 0.6883 - val_loss: 1.3470\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.1739 - val_accuracy: 0.6948 - val_loss: 1.4322\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.1547 - val_accuracy: 0.7143 - val_loss: 1.4987\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.1924 - val_accuracy: 0.7013 - val_loss: 1.3677\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9300 - loss: 0.1734 - val_accuracy: 0.6818 - val_loss: 1.4154\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.1677 - val_accuracy: 0.6948 - val_loss: 1.3975\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.1766 - val_accuracy: 0.7078 - val_loss: 1.4272\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.1680 - val_accuracy: 0.6883 - val_loss: 1.4474\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9300 - loss: 0.1610 - val_accuracy: 0.6948 - val_loss: 1.5986\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.1370 - val_accuracy: 0.7078 - val_loss: 1.4997\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1451 - val_accuracy: 0.6818 - val_loss: 1.4971\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.1580 - val_accuracy: 0.6753 - val_loss: 1.5910\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1516 - val_accuracy: 0.6753 - val_loss: 1.6445\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1462 - val_accuracy: 0.7143 - val_loss: 1.4908\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.1282 - val_accuracy: 0.6494 - val_loss: 1.6670\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1149 - val_accuracy: 0.7403 - val_loss: 1.8566\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9560 - loss: 0.1330 - val_accuracy: 0.6948 - val_loss: 1.7186\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9430 - loss: 0.1297 - val_accuracy: 0.6688 - val_loss: 1.7658\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.1250 - val_accuracy: 0.7078 - val_loss: 1.6392\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1193 - val_accuracy: 0.6688 - val_loss: 1.8524\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9577 - loss: 0.1116 - val_accuracy: 0.7013 - val_loss: 1.7959\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1081 - val_accuracy: 0.7143 - val_loss: 1.7505\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0915 - val_accuracy: 0.6818 - val_loss: 1.8623\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1103 - val_accuracy: 0.6818 - val_loss: 1.9840\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.0892 - val_accuracy: 0.6818 - val_loss: 1.8823\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9691 - loss: 0.0958 - val_accuracy: 0.7078 - val_loss: 1.9001\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1038 - val_accuracy: 0.7078 - val_loss: 1.8776\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9593 - loss: 0.1231 - val_accuracy: 0.6623 - val_loss: 1.8823\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9674 - loss: 0.0980 - val_accuracy: 0.7273 - val_loss: 2.2130\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9593 - loss: 0.1071 - val_accuracy: 0.6883 - val_loss: 1.9530\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0846 - val_accuracy: 0.6753 - val_loss: 2.4688\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9577 - loss: 0.0937 - val_accuracy: 0.6948 - val_loss: 2.1776\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0879 - val_accuracy: 0.6688 - val_loss: 2.1405\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0792 - val_accuracy: 0.6494 - val_loss: 2.3072\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 0.0872 - val_accuracy: 0.7273 - val_loss: 2.2289\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0798 - val_accuracy: 0.7013 - val_loss: 2.4447\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0800 - val_accuracy: 0.7013 - val_loss: 2.3061\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0682 - val_accuracy: 0.6558 - val_loss: 2.3214\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0805 - val_accuracy: 0.6558 - val_loss: 2.4263\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.0824 - val_accuracy: 0.6753 - val_loss: 2.5619\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.0760 - val_accuracy: 0.7273 - val_loss: 2.3351\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0581 - val_accuracy: 0.6558 - val_loss: 2.4198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28342552930>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d328122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
